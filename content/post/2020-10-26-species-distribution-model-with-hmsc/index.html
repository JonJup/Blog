---
title: 'Species distribution model with HMSC '
author: 'Jonathan Jupke '
date: '2020-10-26'
slug: species-distribution-model-with-hmsc
categories: []
tags:
  - R
  - MOD3
  - HMSC
bibliography: ref.bib
images: ~
---

<link href="index_files/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
<script src="index_files/kePrint/kePrint.js"></script>
<link href="index_files/lightable/lightable.css" rel="stylesheet" />


<style>
body {
text-align: justify}
</style>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In this short example, we will use the Hierarchical Modeling of Species Communities (HMSC, <span class="citation">Ovaskainen and Abrego (2020)</span>) approach through its implementation in the HMSC-R package <span class="citation">(Tikhonov et al. 2020)</span> to analyze and predict the distribution of the Western jackdaw (<em>Corvus monedula</em>) in Finland.
This post works through a univariate example of HMSC - if you are interested in a multi-species example, see <a href="https://jonjup.netlify.app/post/2021-01-05-joint-species-distribution-modelling-with-hmsc/joint-species-distribution-modelling-with-hmsc/">here</a>.
However, I suggest you start with the univariate example if you are not familiar with HMSC. This post accompanies the advanced methods in multivariate statistics lecture at the University of Koblenz-Landau.
It will not delve deeply into the theoretical aspects of HMSC but focus on it’s implementation in R.
For more introductory material to HMSC see <span class="citation">Ovaskainen et al. (2017)</span>, <span class="citation">Ovaskainen and Abrego (2020)</span>, or the <a href="https://www.helsinki.fi/en/researchgroups/statistical-ecology/hmsc">official website</a>.</p>
</div>
<div id="preparing-the-analysis" class="section level1">
<h1>Preparing the analysis</h1>
<p>To run this code you will need to install the <em>pacman</em> R package beforehand but this will take care of all the other packages required.</p>
<pre class="r"><code>if(!require(pacman)) install.packages(&quot;pacman&quot;)
p_load(abind,
       data.table,
       dplyr,
       ggplot2,
       here,
       kableExtra,
       Hmsc,
       magrittr,
       stringr)</code></pre>
<p>You can download the data we use <a href="https://www.helsinki.fi/sites/default/files/atoms/files/section_11_1_birds_2020_05_31.zip">here</a>.</p>
<p>We use the Finnish bird data that are often used by the creators of HMSC to demonstrate the method (e.g. Chapter 5 of <span class="citation">Ovaskainen and Abrego (2020)</span> or <span class="citation">Tikhonov et al. (2020)</span>). We will this analysis on the abundance and occurence <em>C. monedula</em> in the year 2014.</p>
<pre class="r"><code># data.directory needs to be a string, pointing 
# to where your data is
data = fread(file.path(data.directory, &quot;data.csv&quot;))
# subset to the year 2014 using data.table syntax
data = data[Year == 2014]
# drop unused factor levels 
# - useful for factors levels missing from 2014
data %&lt;&gt;% droplevels()

# extract environmental covariates 
XData = as.data.frame(data[, c(&quot;Habitat&quot;, &quot;AprMay&quot;)])
names(XData) = c(&quot;hab&quot;, &quot;clim&quot;)

# extract species data 
Y = as.matrix(data$Corvus_monedula)
colnames(Y) = &quot;Corvus monedula&quot;

# extract spatial coordinates 
xy = as.matrix(data[, c(&quot;x&quot;, &quot;y&quot;)])
# the study design matrix - in this case the name of the site
studyDesign = data.frame(route = factor(data$Route))
rownames(xy) = studyDesign[, 1]
# create a spatial random level
rL = HmscRandomLevel(sData = xy)

# define the formula for the model: habitat (a factor) 
# and the raw second order polynomial of climate
XFormula =  ~ hab + poly(clim, degree = 2, raw = TRUE)</code></pre>
<p>In the next step, we define the model using the <code>Hmsc()</code> function.
Most arguments here are self-explanatory but two arguments are worth mentioning:<br />
<i class="fas  fa-caret-right "></i> <em><span style="color:CornflowerBlue">distr</span></em> is the distribution function<br />
<i class="fas  fa-caret-right "></i> <em><span style="color:CornflowerBlue">ranLevels</span></em> needs to be a list, even if you only have one random level.</p>
</div>
<div id="fitting-the-model" class="section level1">
<h1>Fitting the model</h1>
<pre class="r"><code>m_full = Hmsc(Y=Y,
              XData=XData,
              XFormula=XFormula,
              distr = &quot;lognormal poisson&quot;,
              studyDesign = studyDesign,
              ranLevels=list(route=rL))</code></pre>
<p>If you are not familiar with Bayesian models, this step might be unfamiliar to you.
We did not fit the model yet.
We only defined its structure.
In calls to modeling functions, you might be more familiar with, like <code>lm()</code>, <code>glm()</code>, or <code>lme()</code> this happens in one step.<br />
Now let’s have a look at the object we created by defining the model.
From the environment pane, we can see that it has the class Hmsc.
When we enter the object name a string is returned with the number of sampling units, species, environmental covariates, traits and random levels. <code>str()</code> tells us that it is a list with, in this case, 71 objects.</p>
<pre class="r"><code>m_full</code></pre>
<pre><code>## Hmsc object with 137 sampling units, 1 species, 7 covariates, 1 traits and 1 random levels</code></pre>
<p>Next comes the truly time-consuming step: fitting the model with Markov Chain Monte Carlo.
We need to set the number of chains (<em><span style="color:CornflowerBlue">nChains</span></em>), the thinning (<em><span style="color:CornflowerBlue">thin</span></em>), the number of CPU cores to use (<em><span style="color:CornflowerBlue">nParallel</span></em>), the number of samples (<em><span style="color:CornflowerBlue">samples</span></em>), the length of the burn-in or transient (<em><span style="color:CornflowerBlue">transient</span></em>) and the interval at which we want the function to report its progress (<em><span style="color:CornflowerBlue">verbose</span></em>).</p>
<p>In this example, we use three different values for <em><span style="color:CornflowerBlue">thin</span></em> (5,10 and 100) to show how the fit changes.</p>
<p>We fit the models in a loop and store them in a list.
Both steps are not necessary if you only fit a model with one value for each parameter.
A low thinning means the model is fit quicker since fewer samples have to be taken.
However, the chain convergence can be worse because autocorrelation within chains increases.
We should be able to see this with the effective sample size.</p>
<p>When you fit such models you should start with a low thin (like 5) to estimate run time and to get an idea about the general direction of the results.
Even though the estimate will change when you increase the thinning, you are often able to start writing your result section while the larger models are still running.
Simply plug in the estimates from the final model once its done.
You should increase the thinning until the model fit is satisfactory (high effective sampling size, low potential scale reduction factor, converged and stable chains).</p>
<pre class="r"><code>nChains = 2
thin = c(5, 10, 100)
nParallel = max(round(parallel::detectCores() / 2), 
                nChains)
samples = 1000
transient = 500 * thin
verbose = 500 * thin

for (i in seq_along(thin)) {
        model[[i]] = sampleMcmc(
                m_full,
                thin = thin[i],
                samples = samples,
                transient = transient,
                nChains = nChains,
                verbose = verbose,
                initPar = &quot;fixed effects&quot;

        )
}</code></pre>
<p>After fitting the models, we need to convert them into objects that the Coda R-package <span class="citation">(Plummer et al. 2006)</span> can use.
With the coda objects, we can plot trace plots or posterior density estimates for each parameter.</p>
<pre class="r"><code>mpost = list()
for (i in seq_along(model)) {
  mpost[[i]] = convertToCodaObject(model[[i]],
                                   spNamesNumbers = c(T, F),
                                   covNamesNumbers = c(T, F))
}
plot(mpost[[1]]$Beta[, 1:3])</code></pre>
<p><img src="index_files/figure-html/mcmc-plots1-1.png" width="672" /></p>
<pre class="r"><code>plot(mpost[[2]]$Beta[,1:3])</code></pre>
<p><img src="index_files/figure-html/mcmc-plot2-1.png" width="672" /></p>
<pre class="r"><code>plot(mpost[[3]]$Beta[,1:3])</code></pre>
<p><img src="index_files/figure-html/mcmc-plot3-1.png" width="672" /></p>
<p>We can see that a thinning of 100 is necessary to attain satisfactory MCMC convergence.
The potential scale reduction factors (aka Gelman diagnostic) and effective sample sizes confirm this.
Otso Ovaskainen suggests in his lectures that, as a rule of thumb, the latter should be below 1.1.
The effective sample size should be close to the actual sample size (in this case 1000).
Even for the model with a thinning of 100, most effective sample sizes are low.
For a publication, we should further increase the thinning.</p>
<pre class="r"><code>ess.beta = effectiveSize(mpost[[3]]$Beta)</code></pre>
<table class=" lightable-minimal" style='font-family: "Trebuchet MS", verdana, sans-serif; margin-left: auto; margin-right: auto;'>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
ess
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
110.1091
</td>
</tr>
<tr>
<td style="text-align:left;">
habCo
</td>
<td style="text-align:right;">
433.1376
</td>
</tr>
<tr>
<td style="text-align:left;">
habOp
</td>
<td style="text-align:right;">
593.9599
</td>
</tr>
<tr>
<td style="text-align:left;">
habUrb
</td>
<td style="text-align:right;">
787.8184
</td>
</tr>
<tr>
<td style="text-align:left;">
habWe
</td>
<td style="text-align:right;">
236.7238
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(clim, degree = 2, raw = TRUE)1
</td>
<td style="text-align:right;">
184.9870
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(clim, degree = 2, raw = TRUE)2
</td>
<td style="text-align:right;">
404.2062
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>psrf.beta = gelman.diag(mpost[[3]]$Beta,
                         multivariate = FALSE)$psrf</code></pre>
<table class=" lightable-minimal" style='font-family: "Trebuchet MS", verdana, sans-serif; margin-left: auto; margin-right: auto;'>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
psrf.Point.est.
</th>
<th style="text-align:right;">
psrf.Upper.C.I.
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
1.0598018
</td>
<td style="text-align:right;">
1.133281
</td>
</tr>
<tr>
<td style="text-align:left;">
habCo
</td>
<td style="text-align:right;">
0.9995814
</td>
<td style="text-align:right;">
1.000565
</td>
</tr>
<tr>
<td style="text-align:left;">
habOp
</td>
<td style="text-align:right;">
1.0024632
</td>
<td style="text-align:right;">
1.007084
</td>
</tr>
<tr>
<td style="text-align:left;">
habUrb
</td>
<td style="text-align:right;">
0.9996922
</td>
<td style="text-align:right;">
1.001133
</td>
</tr>
<tr>
<td style="text-align:left;">
habWe
</td>
<td style="text-align:right;">
1.0000163
</td>
<td style="text-align:right;">
1.000624
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(clim, degree = 2, raw = TRUE)1
</td>
<td style="text-align:right;">
1.0750217
</td>
<td style="text-align:right;">
1.261937
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(clim, degree = 2, raw = TRUE)2
</td>
<td style="text-align:right;">
1.0630630
</td>
<td style="text-align:right;">
1.245347
</td>
</tr>
</tbody>
</table>
</div>
<div id="assessing-model-fit" class="section level1">
<h1>Assessing model fit</h1>
<p>HMSC has a pair of functions that computes several goodness-of-fit metrics: <code>computePredictedValues()</code> and <code>evaluateModelFit()</code>.
To compare the three thinning values once more, we loop over all three models.
I use two plots to show the results because some metrics are bound between 0 and 1, while others can take larger values.</p>
<pre class="r"><code>MF = list()
for (i in 1:3) {
  preds = computePredictedValues(model[[i]], 
                                 expected = FALSE)
  MF[[i]] = evaluateModelFit(hM = model[[i]], 
                             predY = preds)
}
metrics = names(MF[[1]])
values =
  append(unlist(MF[[1]]),
         append(unlist(MF[[2]]),
                unlist(MF[[3]])))

dt_MF = tibble(
  value = values,
  metric = rep(metrics,
               times = 3),
  thinning = factor(rep(c(5, 10, 100),
                        each = length(MF[[1]])))
)
par(mfrow = c(1,2))
dt_MF %&gt;%
  filter(str_detect(string = metric, pattern = &quot;RMSE&quot;)) %&gt;%
  ggplot(aes(x = metric, y = value, col = thinning)) +
  geom_point(size = 3)</code></pre>
<p><img src="index_files/figure-html/evaluate-model%20fit-1.png" width="672" /></p>
<pre class="r"><code>dt_MF %&gt;%
  filter(str_detect(
    string = metric,
    pattern = &quot;RMSE&quot;,
    negate = TRUE
  )) %&gt;%
  ggplot(aes(x = metric, y = value, col = thinning)) +
  geom_point(size = 3) + 
  ylim(0,1)</code></pre>
<p><img src="index_files/figure-html/evaluate-model%20fit-2.png" width="672" /></p>
<p>Let’s quickly go through these metrics one by one.
RMSE is the <em>Root Mean Square Error</em> between predicted and observed values.
<span class="math inline">\(RMSE = \sqrt{\frac{1}{n}\Sigma_{i=1}^n (y_{ij}-p_{ij}})^2\)</span>, where <span class="math inline">\(y_{ij}\)</span> is the observed value and <span class="math inline">\(p_{ij}\)</span> the value predicted by the model.
In a model with a RSME of 2 (like that with thinning 10) our average prediction is either too large or too small by 2.
As we increase the thinning to 100 the RSME increases to approximately 4.6.
SR2 is a pseudo-<span class="math inline">\(R^2\)</span> that HMSC uses for Poisson-models.
It is computed as the squared Spearman correlation between observed and predicted values, times the sign of the correlation. It ranges between 0 and 1.
Here again, we see that the model with a thinning of 10 has the best fit and the model with a thinning of 100 the worst.<br />
Now we have the same two values again but with a C. in front of it (i.e. C.RMSE and C.SR2). The C. is short for counts.
These values only take into account that the model predicts the counts correctly given that the species occurs.
The model with the best convergence in MCMC (i.e. thinning = 100) has the worst fit (i.e. lowest C.SR2 and highest C.RMSE).
Lastly, there are three more values with O in the beginning.
As you might have figured out by now, the O stands for occurrence.
For these metrics, abundances are censored to presence-absence and we only evaluate whether the model can predict the species’ occurrences accurately.
The three metrics are RSME, TjurR2 and AUC.</p>
<p>AUC is short for Area under the Curve and was proposed by <span class="citation">Pearce and Ferrier (2000)</span>. Tjur R2 is a pseudo-<span class="math inline">\(R^2\)</span> value for binary data such as 0 or 1, presence or absence and was proposed by <span class="citation">Tjur (2009)</span>. We will not get into the details of their computation here but it is important to note that their scales differ.
A model that performs no better than random has an AUC of 0.5 and a perfect model has an AUC of 1. The same models would get Tjur <span class="math inline">\(R^2\)</span> 0 and 1. Thus we can expect the Tjur <span class="math inline">\(R^2\)</span> of a model to be lower than it’s AUC.
Using the AUC in species distribution models was recently criticized by <span class="citation">Jiménez and Soberón (2020)</span>.</p>
</div>
<div id="model-results-and-interpretation" class="section level1">
<h1>Model results and interpretation</h1>
<p>We can use variance partitioning to see how important sets of variables are in determining the abundance of <em>C. monedula</em>.
First, we group all covariates into one of two groups: habitat or climate.
In our example, the number of covariates is low and each group basically represents one variable.
The group habitat represents the factor habitat with all its dummy-variable levels and the group climate the second order polynomial of April and May mean temperatures.
Again we are interested in the results for all three models, to see whether the non-convergent models perform differently.</p>
<pre class="r"><code>groupnames = c(&quot;habitat&quot;, &quot;climate&quot;)
group = c(1, 1, 1, 1, 1, 2, 2)
VP = list()
for (i in 1:3) {
  VP[[i]] = computeVariancePartitioning(model[[i]],
                                        group = group,
                                        groupnames = groupnames)
}
dt_VP = tibble(
  variable = rep(c(&quot;habitat&quot;, &quot;climate&quot;, &quot;Random:route&quot;), times = 3),
  value    = c(c(VP[[1]]$vals), c(VP[[2]]$vals), c(VP[[3]]$vals)),
  thinning = factor(rep(c(5, 10, 100), each = 3))
)

dt_VP %&gt;%
  ggplot(aes(x = variable, y = value, col = thinning)) +
  geom_point(size = 3, position = &quot;jitter&quot;)</code></pre>
<p><img src="index_files/figure-html/variance-partitioning-1.png" width="672" /></p>
<p>From the plot we can see that this is not the case.
All three models agree that climate explains more of the variation than habitat and habitat more than space (which is equal to unexplained variance).</p>
<p>Next, we will predict the probability of occurrence and the abundance of <em>C. monedula</em>.
First along hypothetical gradients of covariates and afterwards across a grid of Finland.</p>
<p>I will only show this with the third model (i.e. thinning = 100) but feel free to try this with the others.
Additionally, we need to transform categorical variable into factors within the model object.
We can construct our artificial gradient with the <code>constructGraident()</code> function.
The function has three arguments: <em><span style="color:CornflowerBlue">hm</span></em> is the model we want to use for the prediction, <em><span style="color:CornflowerBlue">focalVariable</span></em> is the variable our artificial gradient is based on, and <em><span style="color:CornflowerBlue">non.focalVariables</span></em> describes how the other variables are handled.
While the first two arguments are self-explanatory, the third one requires some explanation.
If there are more than one variable in the model, the response of the species could vary along all of them.
As we want to predict the changes in abundance along one focal variable we need to make assumptions about the others.
This assumption can differ between non-focal variables.
Three assumptions are available: 1: the non-focal variable is equal to its overall most common value; 2: the non-focal variable is equal to its most common value conditional on the focal variable; 3: the non-focal variable is fixed at a supplied value.
In the code below, we test the first two options.</p>
<pre class="r"><code>m = model[[3]]
# Convert to factor
m$XData$hab %&lt;&gt;% factor()

Gradient = constructGradient(hM = m, 
                             focalVariable = &quot;clim&quot;,
                             non.focalVariables = list(hab = list(1)))

predY = predict(m,
                Gradient = Gradient, 
                expected = TRUE)

Gradient2 = constructGradient(m,
                              focalVariable = &quot;clim&quot;,
                              non.focalVariables = list(hab = 2))
predY2 = predict(m, 
                Gradient = Gradient2, 
                expected = TRUE)</code></pre>
<pre class="r"><code>plotGradient(m,
             Gradient, 
             pred = predY, 
             measure = &quot;Y&quot;,
             index = 1,
             showData = TRUE)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>plotGradient(m, 
             Gradient2, 
             pred = predY2, 
             measure = &quot;Y&quot;,
             index = 1,
             showData = TRUE)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<p>We can evaluate the predictive performance with cross-validation.
HMSC-R has functions that make this very easy.
The first is <code>createPartition()</code>.
This function takes a model (<em><span style="color:CornflowerBlue">hm</span></em>), the number of folds (<em><span style="color:CornflowerBlue">nfolds</span></em>) and as an optional argument a column which indicates a variable that is used to group observations.
In this case, all observations from the same route are in the same fold.
This function creates an object we can supply to the partition argument of the <code>computePredictedValues()</code> function.</p>
<pre class="r"><code># Create partitions (folds)
partition = list()
MF = list()
for (i in 1:3) {
  partition = createPartition(hM     = model[[i]],
                              nfolds = 2,
                              column = &quot;route&quot;)
  preds = computePredictedValues(model[[i]],
                                 partition = partition)
  MF[[i]] = evaluateModelFit(hM = model[[i]], predY = preds)
  rm(partition, preds)
}</code></pre>
<p>As expected the fit is worse than before.
Especially for the occurrence measures, the measures show that the model is barely better guessing.</p>
<pre class="r"><code>dt_MF = data.table(
  variable = rep(c(&quot;RMSE&quot;, &quot;SR2&quot;, &quot;O.AUC&quot;, &quot;O.TjurR2&quot;, &quot;O.RMSE&quot;, &quot;C.SR2&quot;, &quot;C.RMSE&quot;), times=3),
  value= unlist(lapply(MF, unname)),
  thinning = factor(rep(c(5,10,100), each = 7))
)

par(mfrow = c(1,2))
dt_MF %&gt;%
  filter(str_detect(string = variable, pattern = &quot;RMSE&quot;)) %&gt;%
  ggplot(aes(x = variable, y = value, col = thinning)) +
  geom_point(size = 3)</code></pre>
<p><img src="index_files/figure-html/pred-perf-plot-1.png" width="672" /></p>
<pre class="r"><code>dt_MF %&gt;%
  filter(str_detect(
    string = variable,
    pattern = &quot;RMSE&quot;,
    negate = TRUE
  )) %&gt;%
  ggplot(aes(x = variable, y = value, col = thinning)) +
  geom_point(size = 3) + 
  ylim(0,1)</code></pre>
<p><img src="index_files/figure-html/pred-perf-plot-2.png" width="672" />
Lastly, we also have a grid of values for sampling sites across Finland with their habitat types and climates.
The grid is also part of the data that was linked in the beginning of this post.
Using this data we can predict the occurrence probability and abundance of <em>C. monedula</em> across Finland.</p>
<pre class="r"><code>m = model[[3]]
grid = read.csv(file.path(data.directory,
                          &quot;grid_1000.csv&quot;))
grid = droplevels(subset(grid, !(Habitat==&quot;Ma&quot;)))
xy.grid = as.matrix(cbind(grid$x, grid$y))
XData.grid = data.frame(hab = grid$Habitat,
                        clim = grid$AprMay)
Gradient = prepareGradient(m, XDataNew = XData.grid,
                           sDataNew = list(route = xy.grid))
predY = predict(m, Gradient = Gradient)
EpredY = apply(abind(predY,along = 3), c(1,2), mean)
EpredO = apply(abind(predY,along = 3), c(1,2), FUN =
                       function(a) {mean(a &gt; 0)})
mapData=data.frame(xy.grid, EpredY,EpredO)
names(mapData)=c(&quot;xCoordinates&quot;, &quot;yCoordinates&quot;, &quot;PredictedAbundance&quot;, &quot;PredictedOccurence&quot;)
spO &lt;- ggplot(data = mapData, 
             aes(x= xCoordinates, 
                 y= yCoordinates, 
                 color=PredictedOccurence)
             ) +
  geom_point(size=2)
spC &lt;- ggplot(data = mapData, 
              aes(x= xCoordinates, 
                  y= yCoordinates, 
                  color=PredictedAbundance)
) +
  geom_point(size=2)

spO + 
  ggtitle(&quot;Predicted Corvus monedula occurrence&quot;) +
  xlab(&quot;East coordinate (km)&quot;) + 
  ylab(&quot;North coordinate (km)&quot;) + 
  scale_color_gradient(low = &quot;blue&quot;, 
                       high=&quot;red&quot;, 
                       name =&quot;Occurrence probability&quot;)
spC + 
  ggtitle(&quot;Predicted Corvus monedula abundance&quot;) +
  xlab(&quot;East coordinate (km)&quot;) + 
  ylab(&quot;North coordinate (km)&quot;) + 
  scale_color_gradient(low = &quot;blue&quot;, 
                       high=&quot;red&quot;, 
                       name =&quot;Abundance&quot;)</code></pre>
<p><img src="index_files/figure-html/hmsc-spatial-prediction-hidden-1.png" width="672" /><img src="index_files/figure-html/hmsc-spatial-prediction-hidden-2.png" width="672" /></p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-LauraJimenez2020">
<p>Jiménez, Laura, and J. Soberón. 2020. “Leaving the area under the receiving operating characteristic curve behind: An evaluation method for species distribution modeling applications based on presence-only data.” <em>Methods in Ecology and Evolution</em> 1 (1): 1–2. <a href="https://doi.org/10.1111/j.2041-210x.2010.00016.x">https://doi.org/10.1111/j.2041-210x.2010.00016.x</a>.</p>
</div>
<div id="ref-ovaskainen2020joint">
<p>Ovaskainen, Otso, and Nerea Abrego. 2020. <em>Joint Species Distribution Modelling: With Applications in R</em>. Cambridge University Press.</p>
</div>
<div id="ref-ovaskainen2017make">
<p>Ovaskainen, Otso, Gleb Tikhonov, Anna Norberg, F Guillaume Blanchet, Leo Duan, David Dunson, Tomas Roslin, and Nerea Abrego. 2017. “How to Make More Out of Community Data? A Conceptual Framework and Its Implementation as Models and Software.” <em>Ecology Letters</em> 20 (5): 561–76.</p>
</div>
<div id="ref-pearce2000evaluating">
<p>Pearce, Jennie, and Simon Ferrier. 2000. “Evaluating the Predictive Performance of Habitat Models Developed Using Logistic Regression.” <em>Ecological Modelling</em> 133 (3): 225–45.</p>
</div>
<div id="ref-Plummer2006">
<p>Plummer, Martyn, Nicky Best, Kate Cowles, and Karen Vines. 2006. “CODA: Convergence Diagnosis and Output Analysis for Mcmc.” <em>R News</em> 6 (1): 7–11. <a href="https://journal.r-project.org/archive/">https://journal.r-project.org/archive/</a>.</p>
</div>
<div id="ref-tikhonov2020joint">
<p>Tikhonov, Gleb, Øystein H Opedal, Nerea Abrego, Aleksi Lehikoinen, Melinda MJ de Jonge, Jari Oksanen, and Otso Ovaskainen. 2020. “Joint Species Distribution Modelling with the R-Package Hmsc.” <em>Methods in Ecology and Evolution</em> 11 (3): 442–47.</p>
</div>
<div id="ref-tjur2009coefficients">
<p>Tjur, Tue. 2009. “Coefficients of Determination in Logistic Regression Models—a New Proposal: The Coefficient of Discrimination.” <em>The American Statistician</em> 63 (4): 366–72.</p>
</div>
</div>
</div>
